{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f5b9607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor, Compose, Normalize\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam, AdamW\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.distributions as distributions\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cb143e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RectifiedFlow:\n",
    "  def euler(self,x_t,v,dt):\n",
    "    x_t=x_t+v*dt\n",
    "    return x_t\n",
    "  def create_flow(self,x_1,t):\n",
    "    x_0=torch.randn_like(x_1)\n",
    "    t=t[:,None,None,None]\n",
    "    x_t=t*x_1+(1-t)*x_0\n",
    "    return x_t,x_0\n",
    "  def mse_loss(self,x_1,x_0,v):\n",
    "    loss=F.mse_loss(x_1-x_0,v)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10798aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MiniUnet MNIST 28*28 4090 3G左右显存\n",
    "class DownLayer(nn.Module):\n",
    "    \"\"\"MiniUnet的下采样层 Resnet\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 time_emb_dim=16,\n",
    "                 downsample=False):\n",
    "        super(DownLayer, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels,\n",
    "                               out_channels,\n",
    "                               kernel_size=3,\n",
    "                               padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_channels,\n",
    "                               out_channels,\n",
    "                               kernel_size=3,\n",
    "                               padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "        # 线性层，用于时间编码换通道 [B, dim] -> [B, in_channels]\n",
    "        self.fc = nn.Linear(time_emb_dim, in_channels)\n",
    "\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        else:\n",
    "            self.shortcut = None\n",
    "\n",
    "        # 降采样\n",
    "        self.downsample = downsample\n",
    "        if downsample:\n",
    "            self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "    def forward(self, x, temb):\n",
    "        # x: [B, C, H, W]\n",
    "        res = x\n",
    "        x += self.fc(temb)[:, :, None, None]  # [B, in_channels, 1, 1]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.act(x)\n",
    "\n",
    "        if self.shortcut is not None:\n",
    "            res = self.shortcut(res)\n",
    "\n",
    "        x = x + res\n",
    "\n",
    "        if self.downsample:\n",
    "            x = self.pool(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class UpLayer(nn.Module):\n",
    "    \"\"\"MiniUnet的上采样层\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 time_emb_dim=16,\n",
    "                 upsample=False):\n",
    "        super(UpLayer, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels,\n",
    "                               out_channels,\n",
    "                               kernel_size=3,\n",
    "                               padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_channels,\n",
    "                               out_channels,\n",
    "                               kernel_size=3,\n",
    "                               padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "        # 线性层，用于时间编码换通道\n",
    "        self.fc = nn.Linear(time_emb_dim, in_channels)\n",
    "\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        else:\n",
    "            self.shortcut = None\n",
    "\n",
    "        self.upsample = upsample\n",
    "        if upsample:\n",
    "            self.upsample = nn.Upsample(scale_factor=2)\n",
    "\n",
    "    def forward(self, x, temb):\n",
    "        # 上采样\n",
    "        if self.upsample:\n",
    "            x = self.upsample(x)\n",
    "        res = x\n",
    "\n",
    "        x += self.fc(temb)[:, :, None, None]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.act(x)\n",
    "\n",
    "        if self.shortcut is not None:\n",
    "            res = self.shortcut(res)\n",
    "        x = x + res\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class MiddleLayer(nn.Module):\n",
    "    \"\"\"MiniUnet的中间层\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, time_emb_dim=16):\n",
    "        super(MiddleLayer, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels,\n",
    "                               out_channels,\n",
    "                               kernel_size=3,\n",
    "                               padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_channels,\n",
    "                               out_channels,\n",
    "                               kernel_size=3,\n",
    "                               padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "        # 线性层，用于时间编码换通道\n",
    "        self.fc = nn.Linear(time_emb_dim, in_channels)\n",
    "\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        else:\n",
    "            self.shortcut = None\n",
    "\n",
    "    def forward(self, x, temb):\n",
    "        res = x\n",
    "\n",
    "        x += self.fc(temb)[:, :, None, None]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.act(x)\n",
    "\n",
    "        if self.shortcut is not None:\n",
    "            x = self.shortcut(x)\n",
    "        x = x + res\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class MiniUnet(nn.Module):\n",
    "    \"\"\"采用MiniUnet，对MNIST数据做生成\n",
    "        两个下采样block 一个中间block 两个上采样block\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_channels=16, time_emb_dim=None):\n",
    "        super(MiniUnet, self).__init__()\n",
    "\n",
    "        if time_emb_dim is None:\n",
    "            self.time_emb_dim = base_channels\n",
    "\n",
    "        self.base_channels = base_channels\n",
    "\n",
    "        self.conv_in = nn.Conv2d(1, base_channels, kernel_size=3, padding=1)\n",
    "\n",
    "        # 多个Layer构成block\n",
    "        self.down1 = nn.ModuleList([\n",
    "            DownLayer(base_channels,\n",
    "                      base_channels * 2,\n",
    "                      time_emb_dim=self.time_emb_dim,\n",
    "                      downsample=False),\n",
    "            DownLayer(base_channels * 2,\n",
    "                      base_channels * 2,\n",
    "                      time_emb_dim=self.time_emb_dim)\n",
    "        ])\n",
    "        self.maxpool1 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.down2 = nn.ModuleList([\n",
    "            DownLayer(base_channels * 2,\n",
    "                      base_channels * 4,\n",
    "                      time_emb_dim=self.time_emb_dim,\n",
    "                      downsample=False),\n",
    "            DownLayer(base_channels * 4,\n",
    "                      base_channels * 4,\n",
    "                      time_emb_dim=self.time_emb_dim)\n",
    "        ])\n",
    "        self.maxpool2 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.middle = MiddleLayer(base_channels * 4,\n",
    "                                  base_channels * 4,\n",
    "                                  time_emb_dim=self.time_emb_dim)\n",
    "\n",
    "        self.upsample1 = nn.Upsample(scale_factor=2)\n",
    "        self.up1 = nn.ModuleList([\n",
    "            UpLayer(\n",
    "                base_channels * 8,  # concat\n",
    "                base_channels * 2,\n",
    "                time_emb_dim=self.time_emb_dim,\n",
    "                upsample=False),\n",
    "            UpLayer(base_channels * 2,\n",
    "                    base_channels * 2,\n",
    "                    time_emb_dim=self.time_emb_dim)\n",
    "        ])\n",
    "        self.upsample2 = nn.Upsample(scale_factor=2)\n",
    "        self.up2 = nn.ModuleList([\n",
    "            UpLayer(base_channels * 4,\n",
    "                    base_channels,\n",
    "                    time_emb_dim=self.time_emb_dim,\n",
    "                    upsample=False),\n",
    "            UpLayer(base_channels,\n",
    "                    base_channels,\n",
    "                    time_emb_dim=self.time_emb_dim)\n",
    "        ])\n",
    "\n",
    "        self.conv_out = nn.Conv2d(base_channels, 1, kernel_size=1, padding=0)\n",
    "\n",
    "    def time_emb(self, t, dim):\n",
    "        d=dim//2\n",
    "        w=torch.randn(d,device='cuda')*30\n",
    "        x_proj=t[:,None]*w[None,:]*2*math.pi\n",
    "        return torch.cat([torch.sin(x_proj),torch.cos(x_proj)],dim=-1)\n",
    "\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        \"\"\"前向传播函数\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): 输入数据，维度为[B, C, H, W]\n",
    "            t (torch.Tensor): 时间，维度为[B]\n",
    "        \"\"\"\n",
    "        # x:(B, C, H, W)\n",
    "        # 时间编码加上\n",
    "        x = self.conv_in(x)\n",
    "        # 时间编码\n",
    "        temb = self.time_emb(t, self.base_channels)\n",
    "        # 这里注意，我们把temb和labelemb加起来，作为一个整体的temb输入到MiniUnet中，让模型进行感知！二者编码维度一样，可以直接相加！就把label的条件信息融入进去了！\n",
    "        for layer in self.down1:\n",
    "            x = layer(x, temb)\n",
    "        x1 = x\n",
    "        x = self.maxpool1(x)\n",
    "        for layer in self.down2:\n",
    "            x = layer(x, temb)\n",
    "        x2 = x\n",
    "        x = self.maxpool2(x)\n",
    "\n",
    "        # 中间层\n",
    "        x = self.middle(x, temb)\n",
    "\n",
    "        # 上采样\n",
    "        x = torch.cat([self.upsample1(x), x2], dim=1)\n",
    "        for layer in self.up1:\n",
    "            x = layer(x, temb)\n",
    "        x = torch.cat([self.upsample2(x), x1], dim=1)\n",
    "        for layer in self.up2:\n",
    "            x = layer(x, temb)\n",
    "\n",
    "        x = self.conv_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcb8d6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMA(nn.Module):\n",
    "    def __init__(self, model, decay=0.9999, device=None):\n",
    "        super(EMA, self).__init__()\n",
    "        # make a copy of the model for accumulating moving average of weights\n",
    "        self.module = deepcopy(model)\n",
    "        self.module.eval()\n",
    "        self.decay = decay\n",
    "        self.device = device  # perform EMA on different device from model if set\n",
    "        if self.device is not None:\n",
    "            self.module.to(device=self.device)\n",
    "\n",
    "    def _update(self, model, update_fn):\n",
    "        with torch.no_grad():\n",
    "            for ema_v, model_v in zip(self.module.state_dict().values(),\n",
    "                                      model.state_dict().values()):\n",
    "                if self.device is not None:\n",
    "                    model_v = model_v.to(device=self.device)\n",
    "                ema_v.copy_(update_fn(ema_v, model_v))\n",
    "\n",
    "    def update(self, model):\n",
    "        self._update(\n",
    "            model,\n",
    "            update_fn=lambda e, m: self.decay * e + (1.0 - self.decay) * m\n",
    "        )\n",
    "\n",
    "    def set(self, model):\n",
    "        self._update(\n",
    "            model,\n",
    "            update_fn=lambda e, m: m\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71b212ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved training configuration\n",
    "epochs= 100  # More epochs\n",
    "batch_size= 128  # Larger batch size for more stable gradients\n",
    "lr= 5e-4  # Slightly higher learning rate initially\n",
    "weight_decay= 1e-4  # Less regularization\n",
    "ema_decay= 0.9999\n",
    "grad_clip= 1.0\n",
    "lr_schedule= True\n",
    "step_size= 40  # Reduce LR later\n",
    "gamma= 0.5 # More gradual LR reduction\n",
    "lr_adjust_epoch= 25 # 学习率调整的epoch，降为原有的10%\n",
    "batch_print_interval= 100 # 打印间隔，以batch为单位\n",
    "device= 'cuda' # cuda、cpu、mps(only macbook)\n",
    "checkpoint_save_interval= 10 # 模型保存间隔，以epoch为单位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfd6a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:04<00:00, 2.37MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 304kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:02<00:00, 753kB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.75MB/s]\n",
      "Epoch 0: 100%|██████████| 469/469 [00:21<00:00, 21.77it/s]\n",
      "Epoch 1: 100%|██████████| 469/469 [00:20<00:00, 22.47it/s]\n",
      "Epoch 2: 100%|██████████| 469/469 [00:20<00:00, 23.08it/s]\n",
      "Epoch 3: 100%|██████████| 469/469 [00:20<00:00, 22.87it/s]\n",
      "Epoch 4: 100%|██████████| 469/469 [00:20<00:00, 22.76it/s]\n",
      "Epoch 5: 100%|██████████| 469/469 [00:21<00:00, 21.80it/s]\n",
      "Epoch 6: 100%|██████████| 469/469 [00:20<00:00, 22.49it/s]\n",
      "Epoch 7: 100%|██████████| 469/469 [00:21<00:00, 22.17it/s]\n",
      "Epoch 8: 100%|██████████| 469/469 [00:21<00:00, 21.62it/s]\n",
      "Epoch 9: 100%|██████████| 469/469 [00:20<00:00, 22.62it/s]\n",
      "Epoch 10: 100%|██████████| 469/469 [00:20<00:00, 23.02it/s]\n",
      "Epoch 11: 100%|██████████| 469/469 [00:20<00:00, 22.36it/s]\n",
      "Epoch 12: 100%|██████████| 469/469 [00:19<00:00, 24.03it/s]\n",
      "Epoch 13: 100%|██████████| 469/469 [00:23<00:00, 20.14it/s]\n",
      "Epoch 14: 100%|██████████| 469/469 [00:20<00:00, 23.24it/s]\n",
      "Epoch 15: 100%|██████████| 469/469 [00:20<00:00, 22.64it/s]\n",
      "Epoch 16: 100%|██████████| 469/469 [00:21<00:00, 22.18it/s]\n",
      "Epoch 17: 100%|██████████| 469/469 [00:21<00:00, 21.44it/s]\n",
      "Epoch 18: 100%|██████████| 469/469 [00:20<00:00, 22.44it/s]\n",
      "Epoch 19: 100%|██████████| 469/469 [00:20<00:00, 22.65it/s]\n",
      "Epoch 20: 100%|██████████| 469/469 [00:21<00:00, 21.87it/s]\n",
      "Epoch 21: 100%|██████████| 469/469 [00:22<00:00, 21.10it/s]\n",
      "Epoch 22: 100%|██████████| 469/469 [00:21<00:00, 21.37it/s]\n",
      "Epoch 23: 100%|██████████| 469/469 [00:22<00:00, 21.07it/s]\n",
      "Epoch 24: 100%|██████████| 469/469 [00:21<00:00, 21.36it/s]\n",
      "Epoch 25: 100%|██████████| 469/469 [00:20<00:00, 22.45it/s]\n",
      "Epoch 26: 100%|██████████| 469/469 [00:19<00:00, 23.46it/s]\n",
      "Epoch 27: 100%|██████████| 469/469 [00:21<00:00, 22.14it/s]\n",
      "Epoch 28: 100%|██████████| 469/469 [00:21<00:00, 22.05it/s]\n",
      "Epoch 29: 100%|██████████| 469/469 [00:20<00:00, 22.84it/s]\n",
      "Epoch 30: 100%|██████████| 469/469 [00:22<00:00, 21.28it/s]\n",
      "Epoch 31: 100%|██████████| 469/469 [00:20<00:00, 22.55it/s]\n",
      "Epoch 32: 100%|██████████| 469/469 [00:20<00:00, 22.88it/s]\n",
      "Epoch 33: 100%|██████████| 469/469 [00:21<00:00, 22.26it/s]\n",
      "Epoch 34: 100%|██████████| 469/469 [00:21<00:00, 21.34it/s]\n",
      "Epoch 35: 100%|██████████| 469/469 [00:21<00:00, 21.47it/s]\n",
      "Epoch 36: 100%|██████████| 469/469 [00:20<00:00, 22.43it/s]\n",
      "Epoch 37: 100%|██████████| 469/469 [00:23<00:00, 19.91it/s]\n",
      "Epoch 38: 100%|██████████| 469/469 [00:21<00:00, 21.51it/s]\n",
      "Epoch 39: 100%|██████████| 469/469 [00:21<00:00, 21.73it/s]\n",
      "Epoch 40: 100%|██████████| 469/469 [00:19<00:00, 23.66it/s]\n",
      "Epoch 41: 100%|██████████| 469/469 [00:20<00:00, 22.69it/s]\n",
      "Epoch 42: 100%|██████████| 469/469 [00:20<00:00, 22.71it/s]\n",
      "Epoch 43: 100%|██████████| 469/469 [00:21<00:00, 21.92it/s]\n",
      "Epoch 44: 100%|██████████| 469/469 [00:21<00:00, 21.90it/s]\n",
      "Epoch 45: 100%|██████████| 469/469 [00:20<00:00, 22.47it/s]\n",
      "Epoch 46: 100%|██████████| 469/469 [00:20<00:00, 22.37it/s]\n",
      "Epoch 47: 100%|██████████| 469/469 [00:23<00:00, 20.27it/s]\n",
      "Epoch 48: 100%|██████████| 469/469 [00:20<00:00, 22.51it/s]\n",
      "Epoch 49: 100%|██████████| 469/469 [00:21<00:00, 21.97it/s]\n",
      "Epoch 50: 100%|██████████| 469/469 [00:18<00:00, 25.38it/s]\n",
      "Epoch 51: 100%|██████████| 469/469 [00:20<00:00, 22.46it/s]\n",
      "Epoch 52: 100%|██████████| 469/469 [00:19<00:00, 23.84it/s]\n",
      "Epoch 53: 100%|██████████| 469/469 [00:20<00:00, 23.23it/s]\n",
      "Epoch 54: 100%|██████████| 469/469 [00:22<00:00, 21.21it/s]\n",
      "Epoch 55: 100%|██████████| 469/469 [00:19<00:00, 24.03it/s]\n",
      "Epoch 56: 100%|██████████| 469/469 [00:25<00:00, 18.41it/s]\n",
      "Epoch 57: 100%|██████████| 469/469 [00:22<00:00, 21.07it/s]\n",
      "Epoch 58: 100%|██████████| 469/469 [00:22<00:00, 21.13it/s]\n",
      "Epoch 59: 100%|██████████| 469/469 [00:22<00:00, 21.03it/s]\n",
      "Epoch 60: 100%|██████████| 469/469 [00:24<00:00, 19.35it/s]\n",
      "Epoch 61: 100%|██████████| 469/469 [00:24<00:00, 19.16it/s]\n",
      "Epoch 62: 100%|██████████| 469/469 [00:22<00:00, 20.72it/s]\n",
      "Epoch 63: 100%|██████████| 469/469 [00:21<00:00, 22.26it/s]\n",
      "Epoch 64: 100%|██████████| 469/469 [00:21<00:00, 22.31it/s]\n",
      "Epoch 65: 100%|██████████| 469/469 [00:19<00:00, 23.55it/s]\n",
      "Epoch 66: 100%|██████████| 469/469 [00:23<00:00, 20.34it/s]\n",
      "Epoch 67: 100%|██████████| 469/469 [00:22<00:00, 21.08it/s]\n",
      "Epoch 68: 100%|██████████| 469/469 [00:23<00:00, 20.05it/s]\n",
      "Epoch 69: 100%|██████████| 469/469 [00:22<00:00, 21.31it/s]\n",
      "Epoch 70: 100%|██████████| 469/469 [00:21<00:00, 21.62it/s]\n",
      "Epoch 71: 100%|██████████| 469/469 [00:21<00:00, 21.94it/s]\n",
      "Epoch 72: 100%|██████████| 469/469 [00:20<00:00, 23.00it/s]\n",
      "Epoch 73: 100%|██████████| 469/469 [00:22<00:00, 21.28it/s]\n",
      "Epoch 74: 100%|██████████| 469/469 [00:22<00:00, 21.17it/s]\n",
      "Epoch 75: 100%|██████████| 469/469 [00:22<00:00, 20.71it/s]\n",
      "Epoch 76: 100%|██████████| 469/469 [00:22<00:00, 21.13it/s]\n",
      "Epoch 77: 100%|██████████| 469/469 [00:20<00:00, 22.61it/s]\n",
      "Epoch 78: 100%|██████████| 469/469 [00:20<00:00, 22.53it/s]\n",
      "Epoch 79:  73%|███████▎  | 342/469 [00:15<00:05, 21.18it/s]"
     ]
    }
   ],
   "source": [
    "transform = Compose([ToTensor()])  # 变换成tensor + 变为[0, 1]\n",
    "\n",
    "dataset = MNIST(\n",
    "        root='/workspace/Generative-model-DYI/data',\n",
    "        train=True,  # 6w\n",
    "        download=True,\n",
    "        transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "model=MiniUnet(base_channels=16).to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "schedular = StepLR(optimizer, step_size=step_size, gamma=gamma) \n",
    "rf= RectifiedFlow()\n",
    "ema = EMA(model, decay=0.999, device=device)\n",
    "for epoch in range(epochs):\n",
    "  pbar=tqdm(dataloader,desc=f'Epoch {epoch}')\n",
    "  for data,label in pbar:\n",
    "    x_1=data\n",
    "    t=torch.rand(x_1.size(0))\n",
    "    x_t,x_0=rf.create_flow(x_1,t)\n",
    "    x_t = x_t.to(device)\n",
    "    x_0 = x_0.to(device)\n",
    "    x_1 = x_1.to(device)\n",
    "    t = t.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    v_pred=model(x_t,t)\n",
    "    loss=rf.mse_loss(x_1,x_0,v_pred)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    ema.update(model)\n",
    "  if epoch % 5 == 0:\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'ema_state_dict': ema.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'loss': loss\n",
    "        }, f\"scalar_ckpt_{epoch}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17e02ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sample(model, rf, num_samples, num_steps=50, device='cuda'):\n",
    "    \"\"\"Generate samples using the trained flow matching model\n",
    "    \n",
    "    Args:\n",
    "        model: Trained MiniUnet model\n",
    "        rf: RectifiedFlow instance\n",
    "        num_samples: Number of samples to generate\n",
    "        num_steps: Number of integration steps (improved from using num_samples as steps)\n",
    "        device: Device to run on\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        dt = 1.0 / num_steps  # Use num_steps for better integration\n",
    "        # Start from noise\n",
    "        x_t = torch.randn(num_samples, 1, 28, 28, device=device)\n",
    "        \n",
    "        # Integrate the flow from t=0 to t=1\n",
    "        for i in range(num_steps):\n",
    "            t = torch.full((num_samples,), i * dt, device=device)\n",
    "            v_pred = model(x_t, t)\n",
    "            x_t = rf.euler(x_t, v_pred, dt)\n",
    "        \n",
    "        return x_t\n",
    "\n",
    "def visualize_samples(samples, num_display=16, figsize=(8, 8)):\n",
    "    \"\"\"Visualize generated samples\n",
    "    \n",
    "    Args:\n",
    "        samples: Generated samples tensor [B, 1, 28, 28]\n",
    "        num_display: Number of samples to display\n",
    "        figsize: Figure size\n",
    "    \"\"\"\n",
    "    # Move to CPU and convert to numpy\n",
    "    samples = samples.cpu().numpy()\n",
    "    \n",
    "    # Clamp values to [0, 1] range\n",
    "    samples = np.clip(samples, 0, 1)\n",
    "    \n",
    "    # Calculate grid dimensions\n",
    "    grid_size = int(np.sqrt(num_display))\n",
    "    if grid_size * grid_size < num_display:\n",
    "        grid_size += 1\n",
    "    \n",
    "    fig, axes = plt.subplots(grid_size, grid_size, figsize=figsize)\n",
    "    axes = axes.flatten() if num_display > 1 else [axes]\n",
    "    \n",
    "    for i in range(num_display):\n",
    "        if i < len(samples):\n",
    "            # Remove channel dimension and display\n",
    "            img = samples[i, 0]  # Shape: [28, 28]\n",
    "            axes[i].imshow(img, cmap='gray')\n",
    "            axes[i].axis('off')\n",
    "        else:\n",
    "            axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def generate_samples_with_ema(ema_model, rf, num_samples=16, num_steps=100):\n",
    "    \"\"\"Generate samples using the EMA model directly\n",
    "    \n",
    "    Args:\n",
    "        ema_model: The EMA model (ema.module)\n",
    "        rf: RectifiedFlow instance\n",
    "        num_samples: Number of samples to generate\n",
    "        num_steps: Number of integration steps for better quality\n",
    "    \"\"\"\n",
    "    print(f\"Generating {num_samples} samples using EMA model...\")\n",
    "    print(f\"Using {num_steps} integration steps for high quality...\")\n",
    "    \n",
    "    # Generate samples using the EMA model\n",
    "    samples = sample(ema_model, rf, num_samples, num_steps, device)\n",
    "    \n",
    "    print(\"Visualizing samples...\")\n",
    "    visualize_samples(samples, num_samples)\n",
    "    \n",
    "    return samples\n",
    "\n",
    "# Use the EMA model for sampling (no need to load checkpoint)\n",
    "sampling_model = ema.module\n",
    "sampling_model.eval()\n",
    "\n",
    "# Generate samples directly with the trained EMA model\n",
    "print(\"Using the EMA model for high-quality sample generation...\")\n",
    "samples = generate_samples_with_ema(sampling_model, rf, num_samples=16, num_steps=100)\n",
    "print(\"Sample generation completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
